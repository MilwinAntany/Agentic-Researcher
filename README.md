# ğŸ§‘â€ğŸ”¬ Agentic Researcher â€“ End-to-End AI-Powered Research Assistant

## ğŸ“Œ Two-Line Overview

An AI-powered research assistant that automates topic exploration, question generation, and intelligent synthesis using Large Language Models (LLMs).
Built with modular architecture to support multiple providers like **Ollama** for lightweight and efficient inference.

---

## ğŸ” Project Overview

This project provides an **end-to-end agentic research framework** where users can input a topic, and the system automatically generates research questions, reasons through them, and produces structured insights. It is designed to demonstrate how LLMs can assist in **automated research, planning, and knowledge synthesis**.

---

## âœ¨ Features

* ğŸ“– Automated research planning and question generation
* ğŸ§  LLM-powered reasoning and intelligent synthesis
* ğŸ”„ Modular system with interchangeable LLM providers (e.g., Ollama, OpenAI)
* âš¡ Lightweight and efficient execution with models like `phi3:mini`
* ğŸ“‚ Structured output for further analysis and reporting

---

## ğŸ—ï¸ System Modules

1. **Input Handler** â€“ accepts user research topics
2. **Planner** â€“ generates structured research questions using LLMs
3. **Reasoner** â€“ processes each question and extracts insights
4. **LLM Utility** â€“ abstraction layer for connecting to Ollama or other providers
5. **Orchestrator (Main Script)** â€“ coordinates the entire workflow end-to-end

---

## ğŸ–¼ï¸ System Architecture

```
User Input â†’ Planner â†’ LLM (Ollama/OpenAI) â†’ Reasoner â†’ Synthesized Research Output
```

---

## ğŸ› ï¸ Technologies Used

* **Programming Language**: Python 3.11
* **Libraries**: Ollama Client, argparse, JSON, logging
* **Models**: phi3\:mini, mistral, or other Ollama-supported models
* **IDE**: PyCharm / VSCode

---

## ğŸ’» Hardware Requirements

* Minimum 8 GB RAM (16 GB recommended for smooth inference)
* CPU: Multi-core (GPU optional, depending on model size)
* Disk Space: 5â€“10 GB (for model storage and dependencies)
* OS: Windows / macOS / Linux

---

## ğŸ§ª Testing

* âœ… Unit testing for planner, reasoner, and utils modules
* âœ… Integration testing with Ollama LLM
* âœ… Error handling (e.g., model not found, API issues)
* âœ… End-to-end testing by running sample topics like *AI in healthcare diagnostics*

---

## ğŸ“Š Results

* Successfully generates **relevant research questions** for any given topic
* Provides **structured insights** using lightweight LLM models
* Demonstrates **modular integration** of different AI providers (OpenAI â†’ Ollama migration tested)

---

## ğŸš€ Future Enhancements

* Add **web-based UI** for user interaction
* Expand to support **multiple simultaneous topics**
* Enhance reasoning with **multi-agent collaboration**
* Store research results in a **searchable knowledge base**
* Integrate with **vector databases (e.g., Pinecone, ChromaDB)** for long-term memory

---

## ğŸ“š References

* [Ollama Documentation](https://ollama.ai)
* [LangChain](https://www.langchain.com/)
* [OpenAI API](https://platform.openai.com/)
* Research papers on **Agentic AI Systems** and **LLM Planning & Reasoning**

---
## ğŸ‘¨â€ğŸ’» Developed By
 
- Contact: antanymilwin@gmail.com
